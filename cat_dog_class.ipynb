{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom keras.models import Sequential, Model\nfrom tensorflow.keras import layers\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Define path to the data directory\ndata_dir = Path('../input/dogs-cats-images/dataset')\n\n# Path to train directory\ntrain_dir = data_dir / 'training_set'\n\n# Path to test directory\ntest_dir = data_dir / 'test_set'\n\n!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats_dir = train_dir / 'cats'\ndogs_dir = train_dir / 'dogs'\n\n# Get the list of all the images\ncats = cats_dir.glob('*.jpg')\ndogs = dogs_dir.glob('*.jpg')\n\n# An empty list. We will insert the data into this list in (img_path, label) format\ntrain_data = []\n\n# Go through all the cats. The label for these cases will be 0\nfor img in cats:\n    train_data.append((img,0))\n\n# Go through all the dogs. The label for these cases will be 1\nfor img in dogs:\n    train_data.append((img, 1))\n\n# Get a pandas dataframe from the data we have in our list \ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n\n# Shuffle the data \ntrain_data = train_data.sample(frac=1.).reset_index(drop=True)\n\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count for each class\npets_count = train_data['label'].value_counts()\nprint(pets_count)\n\n#plot the results\nplt.figure(figsize=(10,8))\nsns.barplot(x=pets_count.index, y = pets_count.values)\nplt.title(\"Number of pets\", fontsize=14)\nplt.xlabel(\"Pet\", fontsize=12)\nplt.ylabel(\"Count\", fontsize=12)\nplt.xticks(range(len(pets_count.index)), [\"Cat(0)\", \"Dog(1)\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\ndogs_samples = (train_data[train_data[\"label\"]==1]['image'].iloc[:5]).tolist()\nsamples = cats_samples + dogs_samples\n\nf, ax = plt.subplots(2,5, figsize=(30,10))\nfor i in range(10):\n    img = imread(samples[i])\n    ax[i//5, i%5].imshow(img, cmap='gray')\n    if i < 5:\n        ax[i//5, i%5].set_title(\"Cat\")\n    else:\n        ax[i//5, i%5].set_title(\"Dog\")\n    ax[i//5, i%5].axis('off')\n    ax[i//5, i%5].set_aspect('auto')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nweights1=\"./inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(weights1)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \npre_trained_model.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = layers.Flatten()(last_output)\n\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(1, activation='sigmoid')(x)           \n\nmodel = Model(pre_trained_model.input, x) \n\nopt = Adam(lr=0.001, decay=1e-5)\nes = EarlyStopping(patience=5)\ncheckpoint = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\nmodel.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=opt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n\ntest_datagen = ImageDataGenerator(rescale = 1.0/255.)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))     \n\nvalidation_generator =  test_datagen.flow_from_directory( test_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model\nhistory = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            callbacks=[es, checkpoint],\n            verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc, label='Training')\nplt.plot  ( epochs, val_acc, label='Validation')\nplt.title ('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss, label='Training')\nplt.plot  ( epochs, val_loss, label='Validation')\nplt.legend()\nplt.title ('Training and validation loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#save model\nsaved_model_path = \"./cat_dog_model.h5\"\nmodel.save(saved_model_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,15))\nfor j in range(0,5):\n    for i in range(0,10):\n        plt.subplot(10,10,j*10+i+1)\n        plt.title('%d'%y_test_pred_labels[mn][j*10+i])\n        plt.imshow(x_test[j*10+i].reshape(28,28), cmap=cm.binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://i.ibb.co/sCLbbsF/faisca.jpg\n!wget https://i.ibb.co/zRXPNB2/mufasa.png\n!wget https://i.ibb.co/4SN6cBp/neo.png","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport cv2\n\n\nimage = './faisca.jpg'\nimg = cv2.imread(image,0)\nimg = cv2.resize(img, (150, 150))\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = img.astype(np.float32)/255.\nimg_processed = np.expand_dims(img, axis=0)\nplt.imshow(img_processed)\n#predictions_single = model.predict(img_processed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.imshow(plt.imread(image))\nimg_processed = ImageDataGenerator(rescale = 1.0/255.)\npredictions_single = model.predict(img_processed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_generator =  test_datagen.flow_from_directory( test_dir,\n                                                    batch_size  = 20,\n                                                    class_mode  = 'binary', \n                                                    target_size = (150, 150))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}